{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA 311 UBCO, Boosting implemented in Python**\n",
    "\n",
    "## **Assignment 3, CART:**\n",
    "\n",
    "### **Boosting Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>totalyearlycompensation</th>\n",
       "      <th>yearsofexperience</th>\n",
       "      <th>yearsatcompany</th>\n",
       "      <th>gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>400000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>PhD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>136000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Two Or More</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google</td>\n",
       "      <td>337000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>222000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>310000</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>620000</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apple</td>\n",
       "      <td>180000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>210000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>142000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>242000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  totalyearlycompensation  yearsofexperience  yearsatcompany  \\\n",
       "0     Google                   400000                  5               5   \n",
       "1  Microsoft                   136000                  3               2   \n",
       "2     Google                   337000                  6               6   \n",
       "3  Microsoft                   222000                  4               4   \n",
       "4     Amazon                   310000                 15               3   \n",
       "5     Amazon                   620000                 19               7   \n",
       "6      Apple                   180000                  1               1   \n",
       "7     Amazon                   210000                  4               1   \n",
       "8     Amazon                   142000                  0               0   \n",
       "9   Facebook                   242000                  2               2   \n",
       "\n",
       "  gender         Race          Education  \n",
       "0   Male        Asian                PhD  \n",
       "1   Male  Two Or More  Bachelor's Degree  \n",
       "2   Male        Asian  Bachelor's Degree  \n",
       "3   Male        Asian    Master's Degree  \n",
       "4   Male        Asian  Bachelor's Degree  \n",
       "5   Male        Asian  Bachelor's Degree  \n",
       "6   Male        Asian  Bachelor's Degree  \n",
       "7   Male     Hispanic         Highschool  \n",
       "8   Male        Asian    Master's Degree  \n",
       "9   Male        White    Master's Degree  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##decleration & data first as always\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "# import statsmodels.formula.api as smf\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "df = pd.read_csv('datasalaries.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Testing split, 75% 25% one final time:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company', 'totalyearlycompensation', 'yearsofexperience',\n",
       "       'yearsatcompany', 'gender', 'Race', 'Education'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df.shape[0]\n",
    "i = np.random.permutation(n)\n",
    "\n",
    "train_size = round(0.75*n)\n",
    "test_size = n - train_size\n",
    "\n",
    "train = i[:train_size]\n",
    "test = i[:test_size]\n",
    "\n",
    "training_data = df.iloc[train]\n",
    "testing_data = df.iloc[test]\n",
    "\n",
    "training_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Now, Boosting Implementation:**\n",
    "\n",
    "    we do this with boostModel = GradientBoostingRegressor(max_depth= A , n_estimators= B, random_state= C , loss= loss).fit(x_train, y_train)\n",
    "    Just like before: A is the amount we prune the tree by, B is the number of Trees, & C is the seed\n",
    "    but this time we also have loss: the parameter we seek to minimize; which is either 'huber', 'quantile', 'squared_error', or 'absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.get_dummies(training_data.drop('totalyearlycompensation', axis=1)); y_train = training_data['totalyearlycompensation']\n",
    "\n",
    "boostModel_MSE = GradientBoostingRegressor(max_depth=4, loss='squared_error' , n_estimators=500, random_state=42).fit(x_train, y_train)\n",
    "boostModel_AE  = GradientBoostingRegressor(max_depth=4, loss='absolute_error', n_estimators=500, random_state=42).fit(x_train, y_train)\n",
    "boostModel_H   = GradientBoostingRegressor(max_depth=4, loss='huber'         , n_estimators=500, random_state=42).fit(x_train, y_train)\n",
    "boostModel_QN  = GradientBoostingRegressor(max_depth=4, loss='quantile'      , n_estimators=500, random_state=42).fit(x_train, y_train)\n",
    "\n",
    "# 'huber', 'quantile', 'squared_error', 'absolute_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    to predict we deploy model.predict(x) one last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.get_dummies(testing_data.drop('totalyearlycompensation', axis=1)); y_test = testing_data['totalyearlycompensation']\n",
    "\n",
    "MSE_predictions       = boostModel_MSE      .predict(x_test)\n",
    "AE_predictions        = boostModel_AE       .predict(x_test)\n",
    "H_predictions         = boostModel_H        .predict(x_test)\n",
    "QN_predictions        = boostModel_QN       .predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **& on to our plot:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = boostModel_MSE#.estimators_[0]\n",
    "\n",
    "# plt.figure(figsize=(30, 7))\n",
    "# plot_tree(plot, filled=True, feature_names=x_train.columns); plt.show()# type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar but distinct from R as once again - unlike part 6 this model is deterministic, but the BAgg tree algorithm is implemented differently here & in R\n",
    "also note that unlike part 7 the values of the >/<= 8.5 years experience terminal nodes overlap in value - which is only seen in the RF model\n",
    "\n",
    "### **MSE Time:**\n",
    "\n",
    "heres another table to visualize the error margin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted salary</th>\n",
       "      <th>Pruned Predicted salary</th>\n",
       "      <th>Actual salary</th>\n",
       "      <th>company</th>\n",
       "      <th>yearsofexperience</th>\n",
       "      <th>yearsatcompany</th>\n",
       "      <th>gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>561576</td>\n",
       "      <td>391912</td>\n",
       "      <td>700000</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>592082</td>\n",
       "      <td>343107</td>\n",
       "      <td>650000</td>\n",
       "      <td>Google</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>155963</td>\n",
       "      <td>208469</td>\n",
       "      <td>122000</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6679</th>\n",
       "      <td>260899</td>\n",
       "      <td>274767</td>\n",
       "      <td>280000</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>288993</td>\n",
       "      <td>278572</td>\n",
       "      <td>267000</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>158185</td>\n",
       "      <td>163330</td>\n",
       "      <td>144000</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>316201</td>\n",
       "      <td>232376</td>\n",
       "      <td>330000</td>\n",
       "      <td>Apple</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>142481</td>\n",
       "      <td>207300</td>\n",
       "      <td>120000</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Two Or More</td>\n",
       "      <td>Some College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>387337</td>\n",
       "      <td>211567</td>\n",
       "      <td>455000</td>\n",
       "      <td>Google</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5580</th>\n",
       "      <td>485046</td>\n",
       "      <td>328331</td>\n",
       "      <td>575000</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>155789</td>\n",
       "      <td>282638</td>\n",
       "      <td>175000</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>105702</td>\n",
       "      <td>163330</td>\n",
       "      <td>72000</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>232326</td>\n",
       "      <td>211454</td>\n",
       "      <td>173000</td>\n",
       "      <td>Google</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Master's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>126644</td>\n",
       "      <td>207300</td>\n",
       "      <td>194000</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>190648</td>\n",
       "      <td>210885</td>\n",
       "      <td>160000</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>PhD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted salary  Pruned Predicted salary  Actual salary    company  \\\n",
       "7434            561576                   391912         700000   Facebook   \n",
       "5872            592082                   343107         650000     Google   \n",
       "568             155963                   208469         122000  Microsoft   \n",
       "6679            260899                   274767         280000  Microsoft   \n",
       "7190            288993                   278572         267000     Amazon   \n",
       "5269            158185                   163330         144000     Amazon   \n",
       "641             316201                   232376         330000      Apple   \n",
       "4662            142481                   207300         120000     Amazon   \n",
       "3746            387337                   211567         455000     Google   \n",
       "5580            485046                   328331         575000  Microsoft   \n",
       "4146            155789                   282638         175000  Microsoft   \n",
       "1579            105702                   163330          72000  Microsoft   \n",
       "2851            232326                   211454         173000     Google   \n",
       "6594            126644                   207300         194000      Apple   \n",
       "5910            190648                   210885         160000  Microsoft   \n",
       "\n",
       "      yearsofexperience  yearsatcompany  gender         Race  \\\n",
       "7434                 16               2    Male        White   \n",
       "5872                 16               8    Male        Asian   \n",
       "568                   7               0    Male        White   \n",
       "6679                 12               7    Male        Asian   \n",
       "7190                 12               5    Male        Asian   \n",
       "5269                  0               0    Male        Asian   \n",
       "641                   8               0    Male        Asian   \n",
       "4662                  4               2  Female  Two Or More   \n",
       "3746                  6               5    Male        White   \n",
       "5580                 17              13    Male     Hispanic   \n",
       "4146                 15               0    Male        Asian   \n",
       "1579                  1               1    Male        White   \n",
       "2851                  5               4    Male        White   \n",
       "6594                  4               2  Female        Asian   \n",
       "5910                  6               5    Male     Hispanic   \n",
       "\n",
       "              Education  \n",
       "7434    Master's Degree  \n",
       "5872    Master's Degree  \n",
       "568     Master's Degree  \n",
       "6679    Master's Degree  \n",
       "7190  Bachelor's Degree  \n",
       "5269    Master's Degree  \n",
       "641     Master's Degree  \n",
       "4662       Some College  \n",
       "3746  Bachelor's Degree  \n",
       "5580    Master's Degree  \n",
       "4146    Master's Degree  \n",
       "1579    Master's Degree  \n",
       "2851    Master's Degree  \n",
       "6594  Bachelor's Degree  \n",
       "5910                PhD  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outDF = pd.DataFrame(testing_data)\n",
    "\n",
    "outDF['Predicted salary'] = RF_predictions; outDF['Pruned Predicted salary'] = RF_predictions_pruned\n",
    "outDF['Actual salary'] = outDF['totalyearlycompensation']\n",
    "outDF['Predicted salary'] = outDF['Predicted salary'].astype(int); outDF['Pruned Predicted salary'] = outDF['Pruned Predicted salary'].astype(int)\n",
    "outDF = outDF[['Predicted salary', 'Pruned Predicted salary', 'Actual salary'] + ['company', 'yearsofexperience', 'yearsatcompany', 'gender', 'Race', 'Education']]\n",
    "\n",
    "outDF.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that the pruned tree is occasionally better, but non pruned is superior\n",
    "\n",
    "& now the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned BAgg tree:\n",
      "Average Error:  721.4039320765099 \t Mean Squared Error:  11120732120.931292\n",
      "BAgg tree:\n",
      "Average Error:  -851.1735121174542 \t Mean Squared Error:  3578458680.015494\n"
     ]
    }
   ],
   "source": [
    "print(\"Pruned BAgg tree:\")\n",
    "y_test = testing_data['totalyearlycompensation']\n",
    "pme  =  (y_test - RF_predictions_pruned).mean()\n",
    "pmse = ((y_test - RF_predictions_pruned) ** 2).mean()\n",
    "print(\"Average Error: \", pme, \"\\t Mean Squared Error: \", pmse)\n",
    "\n",
    "print(\"BAgg tree:\")\n",
    "y_test = testing_data['totalyearlycompensation']\n",
    "me  =  (y_test - RF_predictions).mean()\n",
    "mse = ((y_test - RF_predictions) ** 2).mean()\n",
    "print(\"Average Error: \", me, \"\\t Mean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the smaller error for the non pruned tree -- so this model has no over-fit that can be solved with prune, or only has minor amounts of over-fit that only demand mild pruning\n",
    "\n",
    "### **Next Notebooks: Random Forests and Boosting**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
